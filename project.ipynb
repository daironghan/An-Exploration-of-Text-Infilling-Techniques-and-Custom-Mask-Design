{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrVbCy1/L1KxFoymBMMTAx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ECE57000 Final Paper Implementation\n","\n","## An Exploration of Text Infilling Techniques and Custom Mask Design\n","\n","Dai-Rong Han\n"],"metadata":{"id":"J0lEfDQQah-Z"}},{"cell_type":"markdown","source":["## Instructions and Setup\n","\n","Please run this section before continuing.\n","\n","If you want to retrain the model, please follow the steps in the training section.\n","\n","If you only want to see the inference examples, skip the training section."],"metadata":{"id":"fwSnhUQ91jT5"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zXjp1hFAjsQ","executionInfo":{"status":"ok","timestamp":1700525178921,"user_tz":300,"elapsed":993,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"571dbe37-b75c-43ef-ed0b-41e1ef1fb92c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# Wordwrap for better visuals\n","from IPython.display import HTML, display\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"],"metadata":{"id":"44FLzGXYhnai","executionInfo":{"status":"ok","timestamp":1700527561581,"user_tz":300,"elapsed":160,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"9354d6e7-6d16-4625-df28-dc0fc6d09576"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# Clone repository (Already cloned)\n","# Please change to desired path\n","# %cd /content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/Project\n","# ! git clone https://github.com/chrisdonahue/ilm.git\n","# %cd ilm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqHSbHCZBXMb","executionInfo":{"status":"ok","timestamp":1699750457678,"user_tz":300,"elapsed":1695,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"9943d5c5-c077-4128-9820-14de11bfb539"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ilm'...\n","remote: Enumerating objects: 303, done.\u001b[K\n","remote: Counting objects: 100% (62/62), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 303 (delta 54), reused 45 (delta 45), pack-reused 241\u001b[K\n","Receiving objects: 100% (303/303), 1.03 MiB | 7.69 MiB/s, done.\n","Resolving deltas: 100% (126/126), done.\n"]}]},{"cell_type":"code","source":["# Please change to the ilm folder path under where you downloaded this project\n","%cd /content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/Project/ilm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"91Eny1--iLgk","executionInfo":{"status":"ok","timestamp":1700525334099,"user_tz":300,"elapsed":185,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"22c8239c-7085-4c68-cec9-443c9817fd3e"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/size/ilm\n"]}]},{"cell_type":"markdown","source":["## Training\n","Skip if you only want to see inference examples."],"metadata":{"id":"9FCHjuus3k3y"}},{"cell_type":"code","source":["# Install requirements\n","! pip install -r requirements.txt\n","! python -c \"import nltk; nltk.download('punkt')\"\n","! pip install -e .\n","import nltk\n","nltk.download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"b1y9QiiUBt76","executionInfo":{"status":"ok","timestamp":1700525879021,"user_tz":300,"elapsed":20730,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"e76de2fe-1934-402f-da5b-58459d82aaf7"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting boto3==1.13.16 (from -r requirements.txt (line 1))\n","  Downloading boto3-1.13.16-py2.py3-none-any.whl (128 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore==1.16.16 (from -r requirements.txt (line 2))\n","  Downloading botocore-1.16.16-py2.py3-none-any.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2020.4.5.1 (from -r requirements.txt (line 3))\n","  Downloading certifi-2020.4.5.1-py2.py3-none-any.whl (157 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==3.0.4 (from -r requirements.txt (line 4))\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting click==7.1.2 (from -r requirements.txt (line 5))\n","  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 0.7 Requires-Python >=3.6, <3.7; 0.8 Requires-Python >=3.6, <3.7\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement dataclasses==0.7 (from versions: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for dataclasses==0.7\u001b[0m\u001b[31m\n","\u001b[0m[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Obtaining file:///content/gdrive/MyDrive/Colab%20Notebooks/Purdue_ECE570/size/ilm\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Installing collected packages: ilm\n","  Running setup.py develop for ilm\n","Successfully installed ilm-0.0.0\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Download ROC dataset\n","%cd data\n","! chmod +x get_roc_stories.sh\n","! ./get_roc_stories.sh\n","%cd ../"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":662},"id":"TGPNfePAB5_P","executionInfo":{"status":"ok","timestamp":1700525906100,"user_tz":300,"elapsed":20758,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"744c2da1-a7fb-4c7d-d454-a5bbac71afd7"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/size/ilm/data\n","/content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/size/ilm/data/raw_data/roc_stories /content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/size/ilm/data\n","--2023-11-21 00:18:13--  https://docs.google.com/uc?export=download&confirm=&id=15GLH9Kg-U0QANhEOwvgmsXycAO6OPFA7\n","Resolving docs.google.com (docs.google.com)... 142.250.107.139, 142.250.107.138, 142.250.107.100, ...\n","Connecting to docs.google.com (docs.google.com)|142.250.107.139|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-10-2k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/8n7hl7jacegebdp6aljoog11jtrpk5p0/1700525850000/00801004230948063963/*/15GLH9Kg-U0QANhEOwvgmsXycAO6OPFA7?e=download&uuid=e0fd4fee-c5fb-46ec-abcd-2a9968fdb4f5 [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-11-21 00:18:24--  https://doc-10-2k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/8n7hl7jacegebdp6aljoog11jtrpk5p0/1700525850000/00801004230948063963/*/15GLH9Kg-U0QANhEOwvgmsXycAO6OPFA7?e=download&uuid=e0fd4fee-c5fb-46ec-abcd-2a9968fdb4f5\n","Resolving doc-10-2k-docs.googleusercontent.com (doc-10-2k-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n","Connecting to doc-10-2k-docs.googleusercontent.com (doc-10-2k-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9383046 (8.9M) [application/x-gzip]\n","Saving to: ‘roc_stories_split.tar.gz’\n","\n","roc_stories_split.t 100%[===================>]   8.95M  32.3MB/s    in 0.3s    \n","\n","2023-11-21 00:18:24 (32.3 MB/s) - ‘roc_stories_split.tar.gz’ saved [9383046/9383046]\n","\n","train_title.txt\n","test.txt\n","valid.txt\n","test_hand_title.txt\n","e276c999c72d69911e8fc4e376ad81456c04ff769272225919c094a4241d5fd8  test_hand_title.txt\n","6455f283ff08f7ffbd4daabc996b9c7d274bd746b0793f321dcb60a0f2457d3f  test.txt\n","a4cb738a5b0f15686196df41dfd50a99bd4a01f7ed89473a10f52a93a5b481c7  train_title.txt\n","c03956fcee861a25cfd9ca14c4bc79290e7e2748a8f38cfa717b9fcc0e85e7ae  valid.txt\n","If you use this dataset, please cite https://arxiv.org/pdf/1604.01696.pdf (Mostafazadeh et al. 2016)\n","/content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/size/ilm/data\n","/content/gdrive/MyDrive/Colab Notebooks/Purdue_ECE570/size/ilm\n"]}]},{"cell_type":"code","source":["# Split dataset\n","splits = [\"train\", \"valid\"]\n","for SPLIT in splits:\n","    !python create_ilm_examples.py \\\n","        $SPLIT \\\n","        data/char_masks/roc_stories \\\n","        --seed 0 \\\n","        --data_name roc_stories \\\n","        --data_split $SPLIT \\\n","        --mask_cls ilm.mask.custom.MaskCommonNoun \\\n","        --subsample_fraction 0.1"],"metadata":{"id":"h1d8yV35SNjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preview examples (if it can't run, it means that you have not correctly downloaded the dataset or splited it)\n","!python preview_ilm_examples.py \\\n","\tdata/char_masks/roc_stories/train.pkl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"s1Oi0VrlCVxs","executionInfo":{"status":"ok","timestamp":1700526785324,"user_tz":300,"elapsed":2459,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"1427ef74-05d6-46ae-95c7-1a5918d1d898"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Job Problems\n","My work has recently gotten hectic. I haven't handled it properly, and I'm taking it out on my friends. To take care of my problems, I asked for a few days off from work. As time progressed, I made amends and apologized for how I acted. Tomorrow I go back to work, and I can't wait to get back into things.\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","Job Problems\n","My <|MaskCommonNounType.COMMON_NOUN|> has recently gotten hectic. I haven't handled it properly, and I'm taking it out on my <|MaskCommonNounType.COMMON_NOUN|>. To take <|MaskCommonNounType.COMMON_NOUN|> of my <|MaskCommonNounType.COMMON_NOUN|>, I asked for a few <|MaskCommonNounType.COMMON_NOUN|> off from <|MaskCommonNounType.COMMON_NOUN|>. As <|MaskCommonNounType.COMMON_NOUN|> progressed, I made <|MaskCommonNounType.COMMON_NOUN|> and apologized for how I acted. Tomorrow I go back to <|MaskCommonNounType.COMMON_NOUN|>, and I can't wait to get back into <|MaskCommonNounType.COMMON_NOUN|>.\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","work\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","friends\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","care\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","problems\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","days\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","work\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","time\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","amends\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","work\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","things\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Nyla At The Park\n","Nyla was going to the park. She told her mom before she left. Nyla left and walked to the park. Nyla stayed at the park too late. Her mom went to the park and found her.\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|> At The Park\n","Nyla was going to the <|MaskCommonNounType.COMMON_NOUN|>. She told her <|MaskCommonNounType.COMMON_NOUN|> before she left. Nyla left and walked to the <|MaskCommonNounType.COMMON_NOUN|>. Nyla stayed at the <|MaskCommonNounType.COMMON_NOUN|> too late. Her <|MaskCommonNounType.COMMON_NOUN|> went to the <|MaskCommonNounType.COMMON_NOUN|> and found her.\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","Nyla\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","park\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","mom\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","park\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","park\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","mom\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","park\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Jousting\n","Ed was at the Renaissance Festival. He saw men on horseback riding at each other. The men were aiming long pointed sticks at each other! He learned that it was called jousting. Ed thought jousting was fascinating!\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","Jousting\n","Ed was at the Renaissance Festival. He saw <|MaskCommonNounType.COMMON_NOUN|> on <|MaskCommonNounType.COMMON_NOUN|> <|MaskCommonNounType.COMMON_NOUN|> at each other. The <|MaskCommonNounType.COMMON_NOUN|> were aiming long pointed <|MaskCommonNounType.COMMON_NOUN|> at each other! He learned that it was called <|MaskCommonNounType.COMMON_NOUN|>. Ed thought <|MaskCommonNounType.COMMON_NOUN|> was fascinating!\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","men\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","horseback\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","riding\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","men\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","sticks\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","jousting\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","jousting\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Got Away With It\n","Lynn and her friends were in her room laughing hard. They had been out until 3 AM, but no one knew. Her dad sat in the kitchen eating a sandwich, none the wiser. Lynn had never done anything so daring. She decided she would do it again tomorrow.\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","Got Away With It\n","Lynn and her <|MaskCommonNounType.COMMON_NOUN|> were in her <|MaskCommonNounType.COMMON_NOUN|> laughing hard. They had been out until 3 AM, but no one <|MaskCommonNounType.COMMON_NOUN|>. Her <|MaskCommonNounType.COMMON_NOUN|> <|MaskCommonNounType.COMMON_NOUN|> in the <|MaskCommonNounType.COMMON_NOUN|> eating a <|MaskCommonNounType.COMMON_NOUN|>, <|MaskCommonNounType.COMMON_NOUN|> the <|MaskCommonNounType.COMMON_NOUN|>. Lynn had never done <|MaskCommonNounType.COMMON_NOUN|> so daring. She decided she would do it again <|MaskCommonNounType.COMMON_NOUN|>.\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","friends\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","room\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","knew\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","dad\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","sat\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","kitchen\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","sandwich\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","none\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","wiser\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","anything\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","tomorrow\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Beret\n","Freddy wanted to set himself apart from the crowd. He bought a beret and wore it all the time. He thought he pulled it off. His father eventually told him it looked terrible. Freddy bought a beanie to wear instead.\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","Beret\n","Freddy wanted to set himself apart from the <|MaskCommonNounType.COMMON_NOUN|>. He bought a <|MaskCommonNounType.COMMON_NOUN|> and wore it all the <|MaskCommonNounType.COMMON_NOUN|>. He thought he pulled it off. His <|MaskCommonNounType.COMMON_NOUN|> eventually told him it looked terrible. Freddy bought a <|MaskCommonNounType.COMMON_NOUN|> to wear instead.\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","crowd\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","beret\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","time\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","father\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","beanie\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Cheap Meat\n","I went to the store with only five dollars. I wanted to buy some cheap meat. I found some for only one dollar a pound. However, I didn't know what kind of meat it was. I ended up taking it home and eating it all.\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","Cheap Meat\n","I went to the <|MaskCommonNounType.COMMON_NOUN|> with only five <|MaskCommonNounType.COMMON_NOUN|>. I wanted to buy some cheap <|MaskCommonNounType.COMMON_NOUN|>. I found some for only one <|MaskCommonNounType.COMMON_NOUN|> a <|MaskCommonNounType.COMMON_NOUN|>. However, I didn't know what <|MaskCommonNounType.COMMON_NOUN|> of <|MaskCommonNounType.COMMON_NOUN|> it was. I ended up taking it <|MaskCommonNounType.COMMON_NOUN|> and eating it all.\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","store\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","dollars\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","meat\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","dollar\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","pound\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","kind\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","meat\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","home\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Early Bird\n","Jake has never been a coffee drinker. He always just naturally was a morning person. He took a job that required him to be awake at two in the morning. He did this job for three Year's total. Jake is now a coffee drinker.\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","Early Bird\n","Jake has never been a <|MaskCommonNounType.COMMON_NOUN|> <|MaskCommonNounType.COMMON_NOUN|>. He always just naturally was a <|MaskCommonNounType.COMMON_NOUN|> <|MaskCommonNounType.COMMON_NOUN|>. He took a <|MaskCommonNounType.COMMON_NOUN|> that required him to be awake at two in the <|MaskCommonNounType.COMMON_NOUN|>. He did this <|MaskCommonNounType.COMMON_NOUN|> for three <|MaskCommonNounType.COMMON_NOUN|>'s total. Jake is now a <|MaskCommonNounType.COMMON_NOUN|> <|MaskCommonNounType.COMMON_NOUN|>.\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","coffee\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","drinker\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","morning\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","person\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","job\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","morning\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","job\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","Year\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","coffee\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","drinker\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","--------------------------------------------------------------------------------\n","                                    --------\n","                                    ORIGINAL\n","                                    --------\n","Vacation In India\n","Jon's family decided to go to vacation in India. Jon didn't want to go to India. His family dragged him along, anyways. Jon was angry. But, he soon fell in love with India!\n","                                    -------\n","                                    CONTEXT\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|> In India\n","Jon's <|MaskCommonNounType.COMMON_NOUN|> decided to go to <|MaskCommonNounType.COMMON_NOUN|> in India. Jon didn't want to go to India. His <|MaskCommonNounType.COMMON_NOUN|> dragged him along, <|MaskCommonNounType.COMMON_NOUN|>. Jon was angry. But, he soon fell in <|MaskCommonNounType.COMMON_NOUN|> with India!\n","                                    -------\n","                                    ANSWERS\n","                                    -------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","Vacation\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","family\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","vacation\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","family\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","anyways\n","--------------------\n","<|MaskCommonNounType.COMMON_NOUN|>\n","love\n"]}]},{"cell_type":"code","source":["# Install transformers before training and inference example\n","! pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"WdN5QzbVDfEk","executionInfo":{"status":"ok","timestamp":1700526800157,"user_tz":300,"elapsed":8921,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"1c78a0e4-2c85-4f9f-bf3f-6763c5887fa2"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}]},{"cell_type":"code","source":["# Check if GPU is available\n","import torch\n","print(torch.cuda.device_count())\n","print(f'Can I can use GPU now? -- {torch.cuda.is_available()}')\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"_59PIHHSBdIY","executionInfo":{"status":"ok","timestamp":1700526802415,"user_tz":300,"elapsed":7,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"dd284a2f-4bf9-4eea-f5c0-18c528126bda"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0\n","Can I can use GPU now? -- False\n"]}]},{"cell_type":"code","source":["# Train model\n","!python train_ilm.py \\\n","\texperiment_roc_stories \\\n","\ttrain \\\n","\tdata/char_masks/roc_stories \\\n","\t--seed 0 \\\n","\t--train_examples_tag train \\\n","\t--eval_examples_tag valid \\\n","\t--eval_max_num_examples 186 \\\n","\t--mask_cls ilm.mask.custom.MaskCommonNoun"],"metadata":{"id":"lZJb00lvSL70"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"H3dK-YT53xJ3"}},{"cell_type":"code","source":["# Install transformers if needed\n","# ! pip install transformers"],"metadata":{"id":"ubqqfgU7-0iY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Infilling example with retrained model (RM)\n","import os\n","import pickle\n","import ilm.tokenize_util\n","import torch\n","from transformers import GPT2LMHeadModel\n","from ilm.infer import infill_with_ilm\n","print('Infilling example with retrained model (RM)')\n","\n","# Prepare tokenizer\n","MODEL_DIR = \"retrained_model\" # Retrained model path\n","tokenizer = ilm.tokenize_util.Tokenizer.GPT2\n","with open(os.path.join(MODEL_DIR, 'additional_ids_to_tokens.pkl'), 'rb') as f:\n","    additional_ids_to_tokens = pickle.load(f)\n","additional_tokens_to_ids = {v:k for k, v in additional_ids_to_tokens.items()} # Swap key value\n","try:\n","    ilm.tokenize_util.update_tokenizer(additional_ids_to_tokens, tokenizer)\n","except ValueError:\n","    pass # Already updated\n","\n","# Load model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GPT2LMHeadModel.from_pretrained(MODEL_DIR)\n","model.eval()\n","model = model.to(device)\n","\n","# Create context and tokenize\n","# context = \"\"\"\n","# Romantic Date\n","# On the way to meet his girlfriend, Leo stopped by a _ shop. He bought a _ for her.\n","# \"\"\".strip()\n","context = \"\"\"\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at _. He received a _ from his classmates.\n","\"\"\".strip()\n","context_ids = ilm.tokenize_util.encode(context, tokenizer)\n","blank_id = ilm.tokenize_util.encode(' _', tokenizer)[0]\n","context_ids[context_ids.index(blank_id)] = additional_tokens_to_ids['<|infill_common_noun|>']\n","context_ids[context_ids.index(blank_id)] = additional_tokens_to_ids['<|infill_common_noun|>']\n","print('-' * 40)\n","print('Context')\n","print('-' * 40)\n","print(ilm.tokenize_util.decode(context_ids, tokenizer))\n","\n","# Result\n","generated = infill_with_ilm( model, additional_tokens_to_ids, context_ids, num_infills=2)\n","for g in generated:\n","    print('-' * 40)\n","    print('Result')\n","    print('-' * 40)\n","    print(ilm.tokenize_util.decode(g, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"LZLOeM5WFC8_","executionInfo":{"status":"ok","timestamp":1700527911291,"user_tz":300,"elapsed":4308,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"84b9ecf0-0cda-4070-e132-fcec3a985675"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Infilling example with retrained model (RM)\n","----------------------------------------\n","Context\n","----------------------------------------\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at<|infill_common_noun|>. He received a<|infill_common_noun|> from his classmates.\n","----------------------------------------\n","Result\n","----------------------------------------\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at school. He received a call from his classmates.\n","----------------------------------------\n","Result\n","----------------------------------------\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at school. He received a present from his classmates.\n"]}]},{"cell_type":"code","source":["# Infilling example with trained model (TM)\n","import os\n","import pickle\n","import ilm.tokenize_util\n","import torch\n","from transformers import GPT2LMHeadModel\n","from ilm.infer import infill_with_ilm\n","print('Infilling example with trained model (TM)')\n","\n","# Prepare tokenizer\n","MODEL_DIR = \"trained_model\" # Trained model path\n","tokenizer = ilm.tokenize_util.Tokenizer.GPT2\n","with open(os.path.join(MODEL_DIR, 'additional_ids_to_tokens.pkl'), 'rb') as f:\n","    additional_ids_to_tokens = pickle.load(f)\n","additional_tokens_to_ids = {v:k for k, v in additional_ids_to_tokens.items()} # Swap key value\n","try:\n","    ilm.tokenize_util.update_tokenizer(additional_ids_to_tokens, tokenizer)\n","except ValueError:\n","    pass # Already updated\n","\n","# Load model\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = GPT2LMHeadModel.from_pretrained(MODEL_DIR)\n","model.eval()\n","model = model.to(device)\n","\n","# Create context and tokenize\n","# context = \"\"\"\n","# Romantic Date\n","# On the way to meet his girlfriend, Leo stopped by a _ shop. He bought a _ for her.\n","# \"\"\".strip()\n","context = \"\"\"\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at _. He received a _ from his classmates.\n","\"\"\".strip()\n","context_ids = ilm.tokenize_util.encode(context, tokenizer)\n","blank_id = ilm.tokenize_util.encode(' _', tokenizer)[0]\n","context_ids[context_ids.index(blank_id)] = additional_tokens_to_ids['<|infill_word|>']\n","context_ids[context_ids.index(blank_id)] = additional_tokens_to_ids['<|infill_word|>']\n","print('-' * 40)\n","print('Context')\n","print('-' * 40)\n","print(ilm.tokenize_util.decode(context_ids, tokenizer))\n","\n","# Result\n","generated = infill_with_ilm( model, additional_tokens_to_ids, context_ids, num_infills=2)\n","for g in generated:\n","    print('-' * 40)\n","    print('Result')\n","    print('-' * 40)\n","    print(ilm.tokenize_util.decode(g, tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":303},"id":"vo4rW-iDi6Eb","executionInfo":{"status":"ok","timestamp":1700527666606,"user_tz":300,"elapsed":12747,"user":{"displayName":"Amber Han","userId":"17085605372410218136"}},"outputId":"3c381b42-1d70-471d-c8b5-1c2d8ed309ae"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Infilling example with trained model (TM)\n","----------------------------------------\n","Context\n","----------------------------------------\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at<|infill_word|>. He received a<|infill_word|> from his classmates.\n","----------------------------------------\n","Result\n","----------------------------------------\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at home. He received a gift from his classmates.\n","----------------------------------------\n","Result\n","----------------------------------------\n","Leo's Birthday\n","It was Leo's Birthday yesterday. A birthday party was held at school. He received a cake from his classmates.\n"]}]}]}